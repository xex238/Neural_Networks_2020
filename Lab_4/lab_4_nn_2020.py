# -*- coding: utf-8 -*-
"""Lab_4 - NN_2020.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QMxlTdrsdczSI_-UzDo5zcWjTinRymE9

1) Импорт библиотек
"""

import keras
from keras import datasets
from keras.models import load_model
from keras.datasets import cifar10
from keras.datasets import cifar100
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.callbacks import EarlyStopping, ModelCheckpoint

# Отрисовка графиков
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt

# Метрики для построения матрицы ошибок и матрицы метрик
from sklearn.metrics import confusion_matrix, classification_report

import itertools

import os
import pickle
import numpy as np

"""Часть 1. Разработка СНН для датасета CIFAR-10

2) Визуализация датасета
"""

# Загрузка входных данных
(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()

# Составление списка имён с именами объектов на изображениях
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Вывод изображений на экран
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(X_train[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[Y_train[i][0]])
plt.show()

"""3) Предобработка датасета"""

# Нормализация значений
x_train = X_train.astype('float32')/255
x_test = X_test.astype('float32')/255

# Конвертация входных данных в категориальные
y_train = keras.utils.to_categorical(Y_train)
y_test = keras.utils.to_categorical(Y_test)

"""4) Создание модели свёрточной нейронной сети"""

model = Sequential()
model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=2))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(rate=0.25))
model.add(Dense(10, activation='softmax'))

# Вывод информации по модели
print(model.summary())

"""5) Компиляция и обучение модели"""

# Компиляция модели
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Обучение модели с сохранением истории в файл
history = model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data= (x_test, y_test))

"""6) Визуализация значений потерь (loss) и метрики точности (accuracy)"""

# Вывод значений количества потерь (loss) и точности (accuracy) для тестового множества
loss, accuracy = model.evaluate(x_test, y_test)
print('Test:')
print('Loss:', loss)
print('Accuracy:', accuracy)

# Визуализация значений количества потерь (loss) и точности (accuracy) для тестового множества по всем эпохам обучения
fig, axs = plt.subplots(1, 2, figsize=(15,5)) 
# обобщение истории для точности
axs[0].plot(history.history['accuracy']) 
axs[0].plot(history.history['val_accuracy']) 
axs[0].set_title('Model Accuracy')
axs[0].set_ylabel('Accuracy') 
axs[0].set_xlabel('Epoch')
axs[0].legend(['train', 'validate'], loc='upper left')
# обобщение истории для потерь
axs[1].plot(history.history['loss']) 
axs[1].plot(history.history['val_loss']) 
axs[1].set_title('Model Loss')
axs[1].set_ylabel('Loss') 
axs[1].set_xlabel('Epoch')
axs[1].legend(['train', 'validate'], loc='upper left')
plt.show()

# Сохранение и загрузка графиков в виде jpeg файла
from google.colab import files
fig.savefig("Accuracy_Loss_cifar_10.jpg")
#files.download("Accuracy_Loss.jpg")

"""7.1) Прогнозирование меток для обучающего множества"""

# Прогнозирование меток для обучающего множества
y_pred_tr = model.predict(x_train)

"""7.2) Вывод полученных метрик на экран (для обучающего множества)"""

y_pred_train = np.argmax(y_pred_tr, axis=1)
y_true_train = np.argmax(y_train, axis=1)

# Вывод матрицы ошибок (confusion matrix) и матрицы метрик на экран для обучающего множества
cm_train = confusion_matrix(y_true_train, y_pred_train)

print("Confusion matrix:")
print(cm_train) # Вывод на экран матрицы ошибок
print()

print("Computing metrix:")
print(classification_report(y_true_train, y_pred_train, digits=3)) # Вывод на экран значений метрик

"""8.1) Прогнозирование меток для тестового множества множества"""

# Прогнозирование меток для тестового множества
y_pred_te = model.predict(x_test)

"""8.2) Вывод полученных метрик на экран (для тестового множества)"""

y_pred_test = np.argmax(y_pred_te, axis=1)
y_true_test = np.argmax(y_test, axis=1)

# Вывод матрицы ошибок (confusion matrix) и матрицы метрик на экран для обучающего множества
cm_test = confusion_matrix(y_true_test, y_pred_test)

print("Confusion matrix:")
print(cm_test) # Вывод на экран матрицы ошибок
print()

print("Computing metrix:")
print(classification_report(y_true_test, y_pred_test, digits=3)) # Вывод на экран значений метрик

"""9) Сохранение модели и весов в файл"""

import os
from google.colab import files

# Сохранение целых моделей (архитектура + вес + состояние оптимизатора)
model.save("all_model.h5")
#files.download("all_model.h5")

# Сохранение только архитектуры модели
json_string = model.to_json() # Сохранить как json
with open('model_architecture.json', 'w') as f:
  f.write(json_string)
#files.download('model_architecture.json')

# Сохранение только весов модели
model.save_weights("model_weights.h5")
#files.download("model_weights.h5")

# Сохранение/загрузка целых моделей (архитектура + вес + состояние оптимизатора)
from keras.models import load_model
model.save("my_model.h5")
model = load_model("my_model.h5")

# Сохранение/загрузка только архитектуры модели
json_string = model.to_json() # Сохранить как json
yaml_string = model.to_yaml() # Сохранить как YAML
model = model_from_json(json_string) # Реконструкция модели из json
model = model_from_yaml(yaml_string) # Реконструкция модели из YAML

# Сохранение/загрузка только весов модели
model.save_weights("my_model_weights.h5")
model.load_weights("my_model_weights.h5")

"""Часть 2. Разработка СНН для датасета CIFAR-100

10) Импорт данных
"""

from keras.datasets import cifar100
(train_images100, train_labels100), (test_images100, test_labels100) = cifar100.load_data(label_mode= 'fine')

from keras.datasets import cifar10
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

import copy

train_imagesAll = list(copy.deepcopy(train_images))
train_labelsAll = list(copy.deepcopy(train_labels))
test_imagesAll = list(copy.deepcopy(test_images))
test_labelsAll = list(copy.deepcopy(test_labels))

for ind in range (len(train_images100)):
    if train_labels100[ind] == 4 :
        train_imagesAll.append(train_images100[ind])
        train_labelsAll.append(np.array([10], dtype=np.uint8))
    elif train_labels100[ind] == 30 :
        train_imagesAll.append(train_images100[ind])
        train_labelsAll.append(np.array([11], dtype=np.uint8))
    elif train_labels100[ind] == 55 :
        train_imagesAll.append(train_images100[ind])
        train_labelsAll.append(np.array([12], dtype=np.uint8))
    elif train_labels100[ind] == 72 :
        train_imagesAll.append(train_images100[ind])
        train_labelsAll.append(np.array([13], dtype=np.uint8))
    elif train_labels100[ind] == 95 :
        train_imagesAll.append(train_images100[ind])
        train_labelsAll.append(np.array([14], dtype=np.uint8))

for ind in range (len(test_images100)):
    if test_labels100[ind] == 4 :
        test_imagesAll.append(test_images100[ind])
        test_labelsAll.append(np.array([10], dtype=np.uint8))
    elif test_labels100[ind] == 30 :
        test_imagesAll.append(test_images100[ind])
        test_labelsAll.append(np.array([11], dtype=np.uint8))
    elif test_labels100[ind] == 55 :
        test_imagesAll.append(test_images100[ind])
        test_labelsAll.append(np.array([12], dtype=np.uint8))
    elif test_labels100[ind] == 72 :
        test_imagesAll.append(test_images100[ind])
        test_labelsAll.append(np.array([13], dtype=np.uint8))
    elif test_labels100[ind] == 95 :
        test_imagesAll.append(test_images100[ind])
        test_labelsAll.append(np.array([14], dtype=np.uint8))
print(np.unique(train_labelsAll))

"""11) Предобработка данных"""

train_imagesAll = np.array(train_imagesAll)
train_labelsAll = np.array(train_labelsAll)
test_imagesAll = np.array(test_imagesAll)
test_labelsAll = np.array(test_labelsAll)

nRows,nCols,nDims = train_imagesAll.shape[1:]
train_data = train_imagesAll.reshape(train_imagesAll.shape[0], nRows, nCols, nDims)
test_data = test_imagesAll.reshape(test_imagesAll.shape[0], nRows, nCols, nDims)
input_shape = (nRows, nCols, nDims)

# Change to float datatype
train_data = train_data.astype('float32')
test_data = test_data.astype('float32')

# Scale the data to lie between 0 to 1
train_data /= 255
test_data /= 255

# Change the labels from integer to categorical data
train_labels_one_hot = keras.utils.to_categorical(train_labelsAll)
test_labels_one_hot = keras.utils.to_categorical(test_labelsAll)

x_train15 = train_data
y_train15 = train_labels_one_hot
x_test15 = test_data
y_test15 = test_labels_one_hot

"""12.1) Загрузка сохранённой модели CIFAR-10"""

from keras.models import load_model
from google.colab import files
from keras.models import model_from_json

# Загрузка целой модели (архитектура + вес + состояние оптимизатора)
model_100 = load_model("all_model.h5")

# Вывод информации по модели
print(model_100.summary())

"""12.2) Проверка корректности загруженной модели"""

# Прогнозирование меток для обучающего множества
y_pred_tr_100 = model_100.predict(x_test)

y_pred_train_100 = np.argmax(y_pred_tr_100, axis=1)
y_true_train_100 = np.argmax(y_test, axis=1)

# Вывод матрицы ошибок (confusion matrix) и матрицы метрик на экран для обучающего множества
cm_train_100 = confusion_matrix(y_true_train_100, y_pred_train_100)

print("Confusion matrix:")
print(cm_train_100) # Вывод на экран матрицы ошибок
print()

print("Computing metrix:")
print(classification_report(y_true_train_100, y_pred_train_100, digits=3)) # Вывод на экран значений метрик

"""Исходя из полученных значений можно сделать вывод, что модель работает корректно

12.3) Модифицирование загруженной модели
"""

# Удаление последнего слоя (для 10-ти выходных классов) и замена его на новый (для 15 классов (10 классов для cifar-10 + 5 классов cifar-100))
model_100.pop()
model_100.add(Dense(15, activation='softmax'))

# Вывод информации по изменённой модели
print(model_100.summary())

# Получение времени до конца сессии в Google Colab
import time, psutil
uptime = time.time() - psutil.boot_time()
remain = (12*60*60 - uptime) / 60 / 60
print(remain)

"""13) Дообучение модели"""

# Компиляция модели
#model_100.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Дообучение модели с сохранением истории
history_100_2 = model_100.fit(x_train15, y_train15, epochs=2, batch_size=64, verbose=1, validation_data= (x_test15, y_test15))

"""14) Визуализация значений потерь (loss) и метрики точности (accuracy)"""

# Вывод значений количества потерь (loss) и точности (accuracy) для тестового множества
loss_100, accuracy_100 = model_100.evaluate(x_test15, y_test15)
print('Test:')
print('Loss:', loss_100)
print('Accuracy:', accuracy_100)

# Визуализация значений количества потерь (loss) и точности (accuracy) для тестового множества по всем эпохам обучения
fig_100, axs_100 = plt.subplots(1, 2, figsize=(15,5)) 
# обобщение истории для точности
axs_100[0].plot(history_100_2.history['accuracy']) 
axs_100[0].plot(history_100_2.history['val_accuracy']) 
axs_100[0].set_title('Model Accuracy')
axs_100[0].set_ylabel('Accuracy') 
axs_100[0].set_xlabel('Epoch')
axs_100[0].legend(['train', 'validate'], loc='upper left')
# обобщение истории для потерь
axs_100[1].plot(history_100_2.history['loss']) 
axs_100[1].plot(history_100_2.history['val_loss']) 
axs_100[1].set_title('Model Loss')
axs_100[1].set_ylabel('Loss') 
axs_100[1].set_xlabel('Epoch')
axs_100[1].legend(['train', 'validate'], loc='upper left')
plt.show()

# Сохранение и загрузка графиков в виде jpeg файла
from google.colab import files
fig.savefig("Accuracy_Loss_cifar_100.jpg")
#files.download("Accuracy_Loss.jpg")

"""15.1) Прогнозирование меток для обучающего множества"""

# Прогнозирование меток для обучающего множества
y_pred_tr_100 = model_100.predict(x_train15)

"""15.2) Вывод полученных метрик на экран (для обучающего множества)"""

y_pred_train_100 = np.argmax(y_pred_tr_100, axis=1)
y_true_train_100 = np.argmax(y_train15, axis=1)

# Вывод матрицы ошибок (confusion matrix) и матрицы метрик на экран для обучающего множества
cm_train_100 = confusion_matrix(y_true_train_100, y_pred_train_100)

print("Confusion matrix:")
print(cm_train_100) # Вывод на экран матрицы ошибок
print()

print("Computing metrix:")
print(classification_report(y_true_train_100, y_pred_train_100, digits=3)) # Вывод на экран значений метрик

"""16.1) Прогнозирование метрик для тестового множества"""

# Прогнозирование меток для тестового множества
y_pred_te_100 = model_100.predict(x_test15)

"""16.2) Вывод полученных метрик на экран (для тестового множества)"""

y_pred_test_100 = np.argmax(y_pred_te_100, axis=1)
y_true_test_100 = np.argmax(y_test15, axis=1)

# Вывод матрицы ошибок (confusion matrix) и матрицы метрик на экран для обучающего множества
cm_test_100 = confusion_matrix(y_true_test_100, y_pred_test_100)

print("Confusion matrix:")
print(cm_test_100) # Вывод на экран матрицы ошибок
print()

print("Computing metrix:")
print(classification_report(y_true_test_100, y_pred_test_100, digits=3)) # Вывод на экран значений метрик